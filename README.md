# GradientDescent_ML
This is one of the Machine Learning projects that I did during the Data Science bootcamp. 
The objective of this project is to do a prediction on randomly generated data (assumed that there is a linear relation between the variable and the target data) using a simple Linear Regression model with four different approaches:
- using manual calculation 
- using normal equation formula
- using Python's Scikit-Learn library
- using Gradient Descent which is one of the algorithms that is used in Machine Learning for optimization. 

The above experiment demonstrates that:
- The four approaches have a similar result. 
- In the case of Gradient Descent, in order to get a minimum error (MSE or RMSE) as shown in the other approaches, we need to iterate up to 100,000 times with 0.001 learning rate.
- The animated gif shows an illustration on how to reduce the prediction error using Gradient Descent. In this case, I did 100 iterations only.

To see the complete code, please check out the project folder in this following link: https://drive.google.com/drive/folders/1vekhhRqxF3wJ9-ENw_Q6OEXAiYFjyrR_?usp=sharing 
